{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BASELINE USING SMP U-Net\n","metadata":{"execution":{"iopub.status.busy":"2023-06-14T03:57:23.59868Z","iopub.execute_input":"2023-06-14T03:57:23.599101Z","iopub.status.idle":"2023-06-14T03:58:00.964865Z","shell.execute_reply.started":"2023-06-14T03:57:23.599065Z","shell.execute_reply":"2023-06-14T03:58:00.963349Z"}}},{"cell_type":"code","source":"train = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install segmentation_models_pytorch\n# !pip install warmup_scheduler\n# !pip install lion-pytorch\n\nimport sys\nsys.path.append(\"/kaggle/input/efficientnet-pytorch/\")\n!pip install /kaggle/input/segmodelpytorchwheel/wheel/timm-0.6.12-py3-none-any.whl\n!pip install /kaggle/input/segmodelpytorchwheel/wheel/efficientnet_pytorch-0.7.1-py3-none-any.whl\n!pip install /kaggle/input/segmodelpytorchwheel/wheel/pretrainedmodels-0.7.4-py3-none-any.whl\n!pip install /kaggle/input/segmodelpytorchwheel/wheel/segmentation_models_pytorch-0.3.2-py3-none-any.whl\n\n!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp /kaggle/input/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth /root/.cache/torch/hub/checkpoints/efficientnet-b5-586e6cc6.pth","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets import the libraries","metadata":{}},{"cell_type":"code","source":"if train == True:\n    !pip install warmup_scheduler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\nimport matplotlib.pyplot as plt\nimport sys\nimport os\nimport gc\nimport sys\nimport pickle\nimport warnings\nimport math\nimport time\nimport random\nimport argparse\nimport importlib\nfrom tqdm.auto import tqdm\nfrom functools import partial\nsys.path.append(\"/kaggle/input/lion-pytorch/lion-pytorch-main\")\nfrom lion_pytorch import Lion\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport segmentation_models_pytorch as smp\n# from warmup_scheduler import GradualWarmupScheduler\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport datetime","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport cv2\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\nimport json\nfrom PIL import Image\nfrom IPython.display import IFrame\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ssl\nssl._create_default_https_context = ssl._create_unverified_context","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration Class","metadata":{}},{"cell_type":"code","source":"import random\nclass CFG:\n    # ============== comp exp name =============\n    comp_name = 'HuBMAP'\n    exp_name = 'efficientnet-b4'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'HuBMAP-Hacking-the-Human-Vasculature'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n    backbone = 'efficientnet-b5' #'se_resnext50_32x4d'\n\n    in_chans = 3 # 65\n    # ============== training cfg =============\n    size = 512\n    tile_size = 512\n    stride = tile_size // 3\n\n    train_batch_size = 14 # 32\n    valid_batch_size = train_batch_size * 1\n    use_amp = True\n\n#     scheduler = 'GradualWarmupSchedulerV2' # 'GradualWarmupSchedulerV2' # 'CosineAnnealingLR'\n    epochs = 1 # 30\n\n    # adamW warmupあり\n    warmup_factor = 10\n    # lr = 1e-4 / warmup_factor\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n\n\n#     objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n#     metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 2\n\n    seed = 42\n\n    # ============== set dataset path =============\n    print('set dataset path')\n    train_dir = \"/kaggle/input/hubmap-hacking-the-human-vasculature/train\"\n    test_dir = \"/kaggle/input/hubmap-hacking-the-human-vasculature/test\"\n    labels_file = '../input/hubmap-hacking-the-human-vasculature/polygons.jsonl'\n\n    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n\n    submission_dir = outputs_path + 'submissions/'\n    submission_path = submission_dir + f'submission_{exp_name}.csv'\n\n    model_dir = outputs_path + \\\n        f'{comp_name}-models/'\n\n    figures_dir = outputs_path + 'figures/'\n\n    log_dir = outputs_path + 'logs/'\n    log_path = log_dir + f'{exp_name}.txt'\n\n    # ============== augmentation =============\n    \n    train_aug_list = [\n        A.Resize(size, size),\n        A.OneOf([A.HorizontalFlip(p=random.random()),\n                 A.VerticalFlip(p=random.random())],p=random.random()),\n        A.OneOf([A.HorizontalFlip(p=random.random()),\n                 A.VerticalFlip(p=random.random())],p=random.random()),\n        A.OneOf([A.HorizontalFlip(p=random.random()),\n                 A.VerticalFlip(p=random.random())],p=random.random()),\n        A.OneOf([A.HorizontalFlip(p=random.random()),\n                 A.VerticalFlip(p=random.random())],p=random.random()),\n        \n        A.RandomBrightnessContrast(p=random.random()),\n        A.ShiftScaleRotate(p=random.random()),\n        A.OneOf([\n                A.GaussNoise(var_limit=[10, 50]),\n                A.GaussianBlur(),\n                A.MotionBlur(),\n                ], p=random.random()),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=random.random()),\n        A.CoarseDropout(max_holes=1, max_width=int(size * 0.2), max_height=int(size * 0.1), \n                        mask_fill_value=0, p=random.random()),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(),\n    ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(),\n    ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_logger(log_file):\n    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\ndef set_seed(seed=None, cudnn_deterministic=True):\n    if seed is None:\n        seed = 310\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = cudnn_deterministic\n    torch.backends.cudnn.benchmark = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dirs(cfg):\n    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir]:\n        os.makedirs(dir, exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cfg_init(cfg, mode='train'):\n    set_seed(cfg.seed)\n\n    if mode == 'train':\n        make_dirs(cfg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg_init(CFG)\n\nLogger = init_logger(log_file=CFG.log_path)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets read the images","metadata":{}},{"cell_type":"code","source":"# class hubmapDataset(Dataset):\n    \n#     def __init__(self, cfg, transform = False, ):\n        \n#         with open(cfg.labels_file, 'r') as json_file:\n#             self.json_labels = [json.loads(line) for line in json_file]\n    \n#         self.image_dir = cfg.train_dir\n# #         self.transform = transform\n#         self.transform = transform\n\n#     __len__ = lambda self : len(self.json_labels)    \n        \n#     def __getitem__(self, idx):\n        \n#         image_path = os.path.join(self.image_dir, f\"{self.json_labels[idx]['id']}.tif\")\n#         image = Image.open(image_path)\n#         image= np.array(image)\n                \n#         mask = np.zeros((512, 512), dtype=np.float32)\n\n#         for annot in self.json_labels[idx]['annotations']:\n\n#             cords = annot['coordinates']\n            \n# #             if annot['type'] == \"blood_vessel\":\n#             if(1):\n\n#                 for cord in cords:\n                    \n#                     rr, cc = np.array([i[1] for i in cord]), np.asarray([i[0] for i in cord])\n                    \n#                     mask[rr, cc] = 1\n\n        \n        \n\n#         if self.transform:\n#             data = self.transform(image=image, mask=mask)\n        \n#         image = data['image']\n#         mask = data['mask']\n        \n\n#         return image, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n\n    # print(aug)\n    return aug\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = hubmapDataset(CFG,get_transforms(\"train\",CFG))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets make the Loader and Split into train_val ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**20% of the train is split into the validation set**","metadata":{}},{"cell_type":"code","source":"# train_data, val_data = train_test_split(dataset, test_size=0.25, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del dataset\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(train_data), len(val_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader = DataLoader(train_data,\n#                           batch_size=CFG.train_batch_size, \n#                           shuffle=True,drop_last=True)\n# valid_loader = DataLoader(val_data, batch_size=CFG.valid_batch_size,\n#                          shuffle=False,\n#                          drop_last=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del train_data ,val_data\n# gc.collect","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets write the model","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, weight=None):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = smp.Unet(\n            encoder_name=\"efficientnet-b5\", \n            encoder_weights=weight,\n            in_channels=cfg.in_chans,\n            classes=cfg.target_size,\n            activation=\"sigmoid\",\n        )\n\n    def forward(self, image):\n        output = self.encoder(image)\n        # output = output.squeeze(-1)\n        return output\n\n\n# def build_model(cfg, weight=\"imagenet\"):\n#     print('model_name', cfg.model_name)\n#     print('backbone', cfg.backbone)\n\n#     model = CustomModel(cfg, weight)\n#     return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# can add schedulers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport math\nimport time\nimport numpy as np\nimport torch\n\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nif train == True:\n    from warmup_scheduler import GradualWarmupScheduler\n\n\n    class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n        \"\"\"\n        https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n        \"\"\"\n        def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n            super(GradualWarmupSchedulerV2, self).__init__(\n                optimizer, multiplier, total_epoch, after_scheduler)\n\n        def get_lr(self):\n            if self.last_epoch > self.total_epoch:\n                if self.after_scheduler:\n                    if not self.finished:\n                        self.after_scheduler.base_lrs = [\n                            base_lr * self.multiplier for base_lr in self.base_lrs]\n                        self.finished = True\n                    return self.after_scheduler.get_lr()\n                return [base_lr * self.multiplier for base_lr in self.base_lrs]\n            if self.multiplier == 1.0:\n                return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n            else:\n                return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\n    def get_scheduler(cfg, optimizer):\n        scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer, cfg.epochs, eta_min=1e-7)\n        scheduler = GradualWarmupSchedulerV2(\n            optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n\n        return scheduler\n\n    def scheduler_step(scheduler, avg_val_loss, epoch):\n        scheduler.step(epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if train == True:\n#     # model = build_model(CFG)\n#     # model = CustomModel(CFG,\"imagenet\")\n\n#     model = torch.load(\"/kaggle/input/hubmap-model-effnet-unet-30epoch-0-9504/epoch_15_loss_0_9018_effnetb05_unet.pt\")\n\n#     model=model.cuda()\n#     # model.load_state_dict(torch.load(\"/kaggle/input/epoch-5-loss-0-8509-resnet34-deeplabv3/epoch_5_loss_0_8509_resnet34_DeepLabV3.pth\"))\n#     optimizer = Adam(model.parameters(), lr=1e-6) # lr after 30 epch 9.999999999999999e-06\n#     # optimizer = Lion(model.parameters(),lr=CFG.lr,weight_decay=CFG.weight_decay)\n#     scheduler = get_scheduler(CFG, optimizer)\n# else:\n#     model = torch.load(\"/kaggle/input/hubmap-model-effnet-unet-30epoch-0-9504/epoch_15_loss_0_9018_effnetb05_unet.pt\")\n#     model = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = torch.load(\"/kaggle/input/hubmap-model-effnet-unet-30epoch-0-9504/fold_4_epoch_45_loss_0_9018_effnetb05_unet.pt\",map_location=device)\n\n# model = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# predict_mask(img_path,mask_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Losses","metadata":{}},{"cell_type":"code","source":"DiceLoss = smp.losses.DiceLoss(mode='binary')\nBCELoss = smp.losses.SoftBCEWithLogitsLoss(pos_weight=torch.tensor(3))\n\nalpha = 0.7\nbeta = 1 - alpha\nTverskyLoss = smp.losses.TverskyLoss(\n    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n\ndef criterion(y_pred, y_true):\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n#     return BCELoss(y_pred, y_true)\n    return 0.6 * BCELoss(y_pred, y_true) + 0.4 * TverskyLoss(y_pred, y_true)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, device):\n    \n\n#     scaler = GradScaler(enabled=CFG.use_amp)\n    \n    losses = AverageMeter()\n    train_loss = 0\n    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        model.train()\n        images = images.to(device).float()\n        labels = labels.to(device).float()\n        batch_size = labels.size(0)\n        labels = torch.unsqueeze(labels, dim=1)\n        with autocast(CFG.use_amp):\n        \n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        train_loss += loss\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return train_loss/len(train_loader)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(valid_loader, model, criterion, device):\n\n    model.eval()\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n        images = images.to(device).float()\n        labels = labels.to(device).float()\n        labels = torch.unsqueeze(labels, dim=1)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n#             y_preds = torch.squeeze(y_preds, dim=1)\n            loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        \n        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n        images.detach()\n        labels=labels.to('cpu').numpy()\n\n        \n    return losses.avg, y_preds ,labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metric for this compitition","metadata":{}},{"cell_type":"markdown","source":"****Average precission****","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import average_precision_score\n\ndef calculate_average_precision(predicted_masks, true_masks):\n    \"\"\"\n    Calculates the average precision for a segmentation task.\n\n    Args:\n        predicted_masks (numpy.ndarray): Predicted masks with shape (N, H, W).\n        true_masks (torch.Tensor): True masks with shape (N, H, W) or (H, W).\n\n    Returns:\n        float: Average precision score.\n    \"\"\"\n#     if true_masks.dim() == 2:\n#         true_masks = true_masks.unsqueeze(0)  # Add a dimension for the number of samples\n\n    predicted_masks_2d = predicted_masks.reshape(predicted_masks.shape[0], -1)\n    true_masks_2d = true_masks.reshape(true_masks.shape[0], -1)\n\n    ap = average_precision_score(true_masks_2d, predicted_masks_2d, average='macro')\n    return ap\n\ndef calc_ap(true_masks, predicted_masks):\n    true_masks = true_masks.astype(int).flatten()\n    predicted_masks = predicted_masks.flatten()\n\n    best_th = 0\n    best_ap = 0\n    for th in np.array(range(10, 50+1, 2)) / 100:\n        \n        ap = calculate_average_precision(true_masks, (predicted_masks >= th).astype(int))\n        print(f'th: {th}, AvgP: {ap}')\n\n        if ap > best_ap:\n            best_ap = ap\n            best_th = th\n    \n    Logger.info(f'best_th: {best_th}, AvgP: {best_ap}')\n    return best_ap, best_th\n\n\ndef calc_cv(mask_gt, mask_pred):\n    best_ap, best_th = calc_ap(mask_gt, mask_pred)\n\n    return best_ap, best_th","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# if CFG.metric_direction == 'minimize':\n#     best_score = np.inf\n# elif CFG.metric_direction == 'maximize':\n#     best_score = -1\n\n# best_loss = np.inf\n\n# prev_loss_tr = 1\n# prev_loss_vl = 0\n\n# for epoch in range(5):\n\n#     start_time = time.time()\n\n#     # train\n#     avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n\n#     # eval\n#     avg_val_loss, mask_pred, valid_mask_gt  = valid_fn(\n#         valid_loader, model, criterion, device)\n    \n    \n        \n#     scheduler_step(scheduler, avg_val_loss, epoch)\n    \n#     best_ap, best_th = calc_cv(valid_mask_gt, mask_pred)\n\n#     # score = avg_val_loss\n#     score = best_ap\n\n#     elapsed = time.time() - start_time\n    \n#     Logger.info(\n#         f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n#     Logger.info(f'Epoch {epoch+1} - avgScore: {score:.4f}')\n#     Logger.info(\n#         f'Epoch {epoch+1} - avgScore: {score:.4f}')\n\n#     if CFG.metric_direction == 'minimize':\n#         update_best = score < best_score\n#     elif CFG.metric_direction == 'maximize':\n#         update_best = score > best_score\n\n    \n    \n#     if update_best:\n#         best_loss = avg_val_loss\n#         best_score = score\n\n#         Logger.info(\n#             f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n#         Logger.info(\n#             f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n        \n#         torch.save({'model': model.state_dict(),\n#                     'preds': mask_pred},\n#                     CFG.model_dir + f'{CFG.backbone}_best.pth')\n        \n\n# #     if (-( avg_loss - prev_loss_tr )/prev_loss_tr)*100 < 2:\n# #         print(epoch)\n# #         break\n# #     prev_loss_tr = avg_loss\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport copy\n\ndef weighted_average_models(model1, model2, weight=0.7):\n    \"\"\"\n    Returns a model with weighted averaged parameters from model1 and model2.\n\n    Args:\n        model1 (torch.nn.Module): First PyTorch model.\n        model2 (torch.nn.Module): Second PyTorch model.\n        weight (float): Weight for averaging the models (between 0 and 1).\n\n    Returns:\n        torch.nn.Module: New model with weighted averaged parameters.\n    \"\"\"\n    assert 0 <= weight <= 1, \"Weight parameter must be between 0 and 1.\"\n    print(\"weighted averaged model\")\n    # Create a deep copy of model1 to avoid modifying the original models\n    averaged_model = copy.deepcopy(model1)\n\n    # Get the state dictionaries of both models\n    model1_state_dict = model1.state_dict()\n    model2_state_dict = model2.state_dict()\n\n    # Iterate over the parameters and perform the weighted average\n    for param_name in model1_state_dict:\n        model1_param = model1_state_dict[param_name]\n        model2_param = model2_state_dict[param_name]\n        averaged_param = (1 - weight) * model1_param +  weight * model2_param\n        averaged_model.state_dict()[param_name].copy_(averaged_param)\n\n    return averaged_model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nfrom sklearn.model_selection import KFold\nclass PennFudanDataset(torch.utils.data.Dataset):\n    def __init__(self, imgs, masks, transforms=None):\n        self.transforms = transforms\n        # load all image files, sorting them to\n        # ensure that they are aligned\n        self.imgs = imgs#sorted(glob.glob('/kaggle/input/hubmap-making-dataset/train/image/*.png'))\n        self.masks = masks#sorted(glob.glob('/kaggle/input/hubmap-making-dataset/train/mask/*.png'))\n\n    def __getitem__(self, idx):\n        # load images and masks\n        img_path = self.imgs[idx]\n        mask_path = self.masks[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        img = np.array(img)\n        mask = Image.open(mask_path).convert('L')\n        # convert the PIL Image into a numpy array\n        mask = np.array(mask)\n        mask = np.where(mask > 0, 1.0, 0.0)\n        \n        \n        \n        if self.transforms is not None:\n            tr = self.transforms(image=img, image2=mask)\n            img , mask = tr[\"image\"],tr[\"image2\"]\n        \n        else:\n            mask = torch.from_numpy(mask).float()\n            img = torch.from_numpy(img).permute(2,0,1).float()\n#         print(img,mask)      \n        return img, mask\n\n    def __len__(self):\n        return len(self.imgs)\n\nn_imgs = len(glob.glob('/kaggle/input/creating-dataset/train/image/*'))\nn_imgs\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg_path= \"/kaggle/input/creating-dataset/train/image/004daf1cbe75.png\"\nmask_path = \"/kaggle/input/creating-dataset/train/mask/004daf1cbe75_mask.png\"\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Read the PNG file\ndef predict_mask(model,img_path,mask_path):\n    image = mpimg.imread(img_path)\n\n    # Read another image for comparison\n\n    another_image = mpimg.imread(mask_path)\n\n    # Create a figure with two subplots\n    fig, axes = plt.subplots(1, 3)\n\n    # Display the first image in the first subplot\n    axes[0].imshow(image)\n    axes[0].set_title('Image 1')\n\n    # Display the second image in the second subplot\n    axes[1].imshow(another_image)\n    axes[1].set_title('Image 2')\n    x = torch.from_numpy(image)\n    x = x.permute(2,0,1)\n    axes[2].imshow(predict(model,x))\n    # Adjust spacing between subplots\n    plt.tight_layout()\n\n    # Show the plot\n    plt.show()\n\ndef predict(model,x):\n    model = model.to(device)\n    model.eval()\n    with torch.no_grad():\n        y = model(x.unsqueeze(dim=0).to(device))\n\n    y = y/torch.max(y).item()\n    y = torch.where(y < 0.5, torch.tensor(0.0), torch.tensor(1.0))\n    numpy_image = torchvision.transforms.ToPILImage()(y.squeeze(0)).convert(\"RGB\")\n    return numpy_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nif CFG.metric_direction == 'minimize':\n    best_score = np.inf\nelif CFG.metric_direction == 'maximize':\n    best_score = -1\ntorch.cuda.empty_cache()\nbest_loss = np.inf\n\nprev_loss_tr = 1\nprev_loss_vl = 0\nmodel = torch.load(\"/kaggle/input/hubmap-model-effnet-unet-30epoch-0-9504/fold_4_epoch_45_loss_0_9018_effnetb05_unet.pt\")\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nfor i, (train_index, test_index) in enumerate(kf.split(range(n_imgs))):\n    fold = i\n    print(fold)\n#     if i!=0: continue\n    all_imgs = sorted(glob.glob('/kaggle/input/creating-dataset/train/image/*.png'))\n    all_masks = sorted(glob.glob('/kaggle/input/creating-dataset/train/mask/*.png'))\n    \n    all_imgs = np.array(all_imgs)\n    all_masks = np.array(all_masks)\n    train_img = all_imgs[train_index]\n    train_mask = all_masks[train_index]\n    val_img = all_imgs[test_index]\n    val_mask = all_masks[test_index]\n    \n    dataset_train = PennFudanDataset(train_img, train_mask,get_transforms(data='train', cfg=CFG))\n    dataset_val = PennFudanDataset(val_img, val_mask,get_transforms(data='valid', cfg=CFG))\n    \n    train_loader = torch.utils.data.DataLoader(\n        dataset_train, batch_size=8, shuffle=True, num_workers=os.cpu_count(), pin_memory=True, drop_last=True)\n    valid_loader = torch.utils.data.DataLoader(\n        dataset_val, batch_size=1, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)    \n    del dataset_val,dataset_train\n    gc.collect()\n    if fold > 1:\n        model0 = torch.load(f\"/kaggle/working/fold_{fold-2}_epoch_45_loss_0_9018_effnetb05_unet.pt\")\n        model1 = torch.load(f\"/kaggle/working/fold_{fold-1}_epoch_45_loss_0_9018_effnetb05_unet.pt\")\n        model  = weighted_average_models(model0,model1)\n    model = model.cuda()\n    \n    optimizer = Adam(model.parameters(), lr=1e-5) # lr after 30 epch 9.999999999999999e-06\n#     optimizer = Lion(model.parameters(),lr=CFG.lr,weight_decay=CFG.weight_decay)\n    scheduler = get_scheduler(CFG, optimizer)\n    \n    \n    for epoch in range(10):\n        print(f\"epoch: {epoch}\")\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, device)\n\n        # eval\n        avg_val_loss, mask_pred, valid_mask_gt  = valid_fn(\n            valid_loader, model, criterion, device)\n\n\n\n        scheduler_step(scheduler, avg_val_loss, epoch)\n\n        best_ap, best_th = calc_cv(valid_mask_gt, mask_pred)\n\n        # score = avg_val_loss\n        score = best_ap\n\n        elapsed = time.time() - start_time\n\n        Logger.info(\n            f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        Logger.info(f'Epoch {epoch+1} - avgScore: {score:.4f}')\n        Logger.info(\n            f'Epoch {epoch+1} - avgScore: {score:.4f}')\n\n        if CFG.metric_direction == 'minimize':\n            update_best = score < best_score\n        elif CFG.metric_direction == 'maximize':\n            update_best = score > best_score\n\n\n\n        if update_best:\n            best_loss = avg_val_loss\n            best_score = score\n\n            Logger.info(\n                f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            Logger.info(\n                f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n\n            torch.save({'model': model.state_dict(),\n                        'preds': mask_pred},\n                        CFG.model_dir + f'{CFG.backbone}_best.pth')\n    predict_mask(model,img_path,mask_path)\n    del train_loader\n    del valid_loader\n    gc.collect()\n    torch.save(model,f\"/kaggle/working/fold_{fold}_epoch_45_loss_0_9018_effnetb05_unet.pt\")\n    #     if (-( avg_loss - prev_loss_tr )/prev_loss_tr)*100 < 2:\n    #         print(epoch)\n    #         break\n    #     prev_loss_tr = avg_loss\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,\"/kaggle/working/epoch_40_loss_0_9018_effnetb05_unet.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\ndisplay(FileLink(\"epoch_15_loss_0_9018_effnetb05_unet.pt\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --no-index --no-deps /kaggle/input/pycocotools-206/wheels/*.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # !pip install --no-index --no-deps /kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\n# import \n# import base64\n# import numpy as np\n# from pycocotools import _mask as coco_mask\n# import typing as t\n# import zlib\n# import os\n# import cv2\n# import matplotlib.pyplot as plt\n# import pandas as pd\n\n# def encode_binary_mask(mask: np.ndarray) -> t.Text:\n#     \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n\n#     # check input mask --\n#     if mask.dtype != bool:\n#         raise ValueError(\n#             \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n#             mask.dtype)\n\n#     mask = np.squeeze(mask)\n#     if len(mask.shape) != 2:\n#         raise ValueError(\n#             \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n#             mask.shape)\n\n#     # convert input mask to expected COCO API input --\n#     mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n#     mask_to_encode = mask_to_encode.astype(np.uint8)\n#     mask_to_encode = np.asfortranarray(mask_to_encode)\n\n#     # RLE encode mask --\n#     encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n#     # compress and base64 encoding --\n#     binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n#     base64_str = base64.b64encode(binary_str)\n#     return base64_str\n\n# def get_pred_string(objs):\n\n#     string = \"\"\n#     for i, item in enumerate(objs):\n# #         mask = np.zeros((512,512), np.bool8) #change here\n# #         mask[item>0] = 1\n#         mask_array = np.zeros((512, 512),np.bool8)\n\n#     # Set mask values to 1 where input_array > 0\n#         mask_array[np.sum(objs, axis=2) > 0] = 1\n# #         print(item.shape)\n#         encoded_mask = encode_binary_mask(mask_array).decode(\"utf-8\")\n\n#         if i == 0:\n#             string += f\"0 1.0 {encoded_mask}\"\n#         else:\n#             string += f\" 0 1.0 {encoded_mask}\"\n        \n#     return string\n\n\n\n# test_path = \"/kaggle/input/hubmap-hacking-the-human-vasculature/test/\"\n# submission = pd.DataFrame()\n\n# ids = []\n# h = []\n# w = []\n# pred_strings = []\n    \n# for img_id in os.listdir(test_path):\n#     curr_img = cv2.imread(test_path + img_id)\n#     ## Get id, height, width\n#     height, width, channels = curr_img.shape\n#     curr_img = torch.from_numpy(cv2.imread(test_path + img_id)).permute(2,0,1)\n#     ids.append(img_id.split(\".\")[0])\n#     h.append(height)\n#     w.append(width)\n    \n    \n    \n#     ## Get prediction_string\n#     pred_strings.append(get_pred_string(curr_img))\n\n# submission[\"id\"] = ids\n# submission[\"height\"] = h\n# submission[\"width\"] = w\n# submission[\"prediction_string\"] = pred_strings\n# submission.set_index(\"id\", inplace=True)\n# submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}